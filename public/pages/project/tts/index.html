	<!DOCTYPE html>
	<html lang="zxx" class="no-js">
	<head>
		<!-- Global site tag (gtag.js) - Google Analytics -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=UA-129902521-1"></script>
		<script>
  		  window.dataLayer = window.dataLayer || [];
  		  function gtag(){dataLayer.push(arguments);}
 		  gtag('js', new Date());
 		  gtag('config', 'UA-129902521-1');
		</script>
		<!-- Mobile Specific Meta -->
		<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
		<!-- Favicon-->
		<link rel="shortcut icon" type="image/png" href="/public/img/favicon.png">
		<!-- Author Meta -->
		<meta name="author" content="colorlib">
		<!-- Meta Description -->
		<meta name="description" content="">
		<!-- Meta Keyword -->
		<meta name="keywords" content="">
		<!-- meta character set -->
		<meta charset="UTF-8">
		<!-- Site Title -->
		<title>Text to Speech without Text</title>

		<link href="https://fonts.googleapis.com/css?family=Poppins:100,200,400,300,500,600,700" rel="stylesheet"> 
			<!--
			CSS
			============================================= -->
			<link rel="stylesheet" href="/public/css/linearicons.css">
			<link rel="stylesheet" href="/public/css/owl.carousel.css">
			<link rel="stylesheet" href="/public/css/font-awesome.min.css">
			<link rel="stylesheet" href="/public/css/nice-select.css">			
			<link rel="stylesheet" href="/public/css/magnific-popup.css">
			<link rel="stylesheet" href="/public/css/bootstrap.css">
			<link rel="stylesheet" href="/public/css/main.css">
			<link rel="stylesheet" href="/public/share/navbar/myNavbar.css">
		</head>
		<body>
			<div class="protfolio-wrap">

			<!-- Start Header Area -->
			<header class="default-header">
				<nav id="myNavbar" class="navbar navbar-expand-lg  navbar-light"></nav>
			</header>
		
			<!-- About Generic Start -->
			<div class="main-wrapper">
				<!-- Start Generic Area -->
				<section class="about-generic-area section-gap">
					<div class="container border-top-generic">
						<div class="col-md-10 center justify-content-md-center">
							<h3 class="about-title mb-30">Text to Speech without Text</h3>
							<h5 class="mb-30">Team Project @ CSIE5431 Applied Deep Learning</h5>
							<p class="mb-30">Compare MBV and VQVAE for discrete representations of subword units in the ZeroSpeech 2019 Challenge.</p>
						</div>
						<div class="row justify-content-md-center">
							<div class="col-md-10">
								<div class="img-text center">
									<img style='width: 80%;' src="/public/pages/project/tts/img/schema.png" alt="result" class="img-fluid mb-20">
									<p style="text-align: center">Figure 1. MBV and VQVAE model architecture.</p>
								</div>
							</div>
						</div>
						<div class="row justify-content-md-center">
							<div class="col-lg-10">
								<p>The underlying training methods on text to speech usually require the large quantity of labeled training data, including text labels or phoneme labels. However, it is quiet challenging and costly to collect high-quality parallel corpora for the low-resourced languages. In this project, we compare the <a href="https://arxiv.org/pdf/1905.11563.pdf">Multilabel-Binary Vectors (MBV) autoencoder</a> and the <a href="https://arxiv.org/pdf/1905.11449.pdf">Vector Quantized Variational Autoencoder (VQVAE)</a>. These two methods share a similar autoencoder backbone while trying to discretize the continuous output of the encoder in a different manner, which are listed above in Figure 1. </p>
							</div>
						</div>

						<div class="row justify-content-md-center">
							<div class="col-md-10">
								<div class="img-text center">
									<table>
										<tr>
											<td>Source</td>
											<td><audio src="/public/pages/project/tts/audio/Source.wav" controls preload></audio></td>
											<td>Continuous</td>
											<td><audio src="/public/pages/project/tts/audio/Continous.wav" controls preload></audio></td>
										</tr>
										<tr>
											<td>MBV</td>
											<td><audio src="/public/pages/project/tts/audio/MBV.wav" controls preload></audio></td>
											<td>MBV-ADV</td>
											<td><audio src="/public/pages/project/tts/audio/MBVADV.wav" controls preload></audio></td>
										</tr>
										<tr>
											<td>VQVAEv1</td>
											<td><audio src="/public/pages/project/tts/audio/VQVAEv1.wav" controls preload></audio></td>
											<td>VQVAEv2</td>
											<td><audio src="/public/pages/project/tts/audio/VQVAEv2.wav" controls preload></audio></td>
										</tr>
									</table>
									
									<p style="text-align: center">Figure 2. Speech samples for voice conversion.</p>
								</div>
							</div>
						</div>

						<div class="row justify-content-md-center">
							<div class="col-lg-10">
								<p>In order to improve the performances and explore the trade-offs, we introduced different techniques including adversarial learning and vector quantized. For the evaluation, we first compare same-speaker reconstruction in training loss, spectrogram, and voice sample. After that, we generate speech as voice conversion task and compare in terms of bitrate and quality which is shown above in Figure 2. For more information, please refer to our report. </p>
							</div>
						</div>

						<div class="row justify-content-md-center text-center">
							<div class="col-md-2">
								<a style="text-align: center" href="/public/pages/project/tts/pdf/report.pdf" class="genric-btn primary-border radius">Report</a>
							</div>
						</div>
					</div>
				</section>
				<!-- End Generic Start -->		
				<!-- start footer Area -->		
				<footer id="myFooter" class="footer-area section-gap"></footer>	
				<!-- End footer Area -->	
			</div>
			<!-- Script for navbar -->
			<script src="/public/js/vendor/jquery-2.2.4.min.js"></script>
			<script src="/public/js/vendor/bootstrap.min.js"></script>	
			<!-- My Own Script-->
			<script src="/public/share/navbar/myNavbar.js"></script>
			<script src="/public/share/footer/myFooter.js"></script>
		</body>
	</html>
